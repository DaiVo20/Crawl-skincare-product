{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_in_page_url = \"https://shopee.vn/api/v4/search/search_items?by=relevancy&limit=50&match_id=2341&newest={}&order=desc&page_type=search&scenario=PAGE_OTHERS&version=2\"\n",
    "rating_url = \"https://shopee.vn/api/v2/item/get_ratings?filter=0&flag=1&itemid={}&limit=6&offset={}&shopid={}&type=0\"\n",
    "\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36',\n",
    "           'x-requested-with': 'XMLHttpRequest'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(reponse):\n",
    "    print(\"Status code: {}\".format(reponse.status_code), end=\" \")\n",
    "    check = True\n",
    "    if (reponse.status_code != 200):\n",
    "        check = False\n",
    "        print(\"-> Fail\")\n",
    "    else:\n",
    "        print(\"-> OK\")\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_product(n_begin, n_end):\n",
    "    product_attr = []\n",
    "    product_id, shop_id, name, brand = [], [], [], []\n",
    "    view_count, shop_location, sold, price = [], [], [], []\n",
    "    variations, rating_star, rating_count = [], [], []\n",
    "\n",
    "    # Crawl products from 1-N_page\n",
    "    for i, key in enumerate(range(n_begin-1, (n_end-1)*50+1, 50)):\n",
    "        print(\"Crawl page: \", i+1)\n",
    "        reponse = requests.get(\n",
    "            product_in_page_url.format(key), headers=headers)\n",
    "        if (check_status(reponse) != True):\n",
    "            break\n",
    "        product_items = json.loads(reponse.text)[\"items\"]\n",
    "\n",
    "        # Get item from product in page i_th\n",
    "        for j in range(50):\n",
    "            print(\"\\tCrawl {}_th product in page {}!->OK\".format(j, i+1))\n",
    "            item_basic = product_items[j][\"item_basic\"]\n",
    "            product_id.append(item_basic[\"itemid\"])\n",
    "            shop_id.append(item_basic[\"shopid\"])\n",
    "            name.append(item_basic[\"name\"])\n",
    "            variations.append(item_basic[\"tier_variations\"][0][\"options\"])\n",
    "            brand.append(item_basic[\"brand\"])\n",
    "            view_count.append(item_basic[\"view_count\"])\n",
    "            shop_location.append(item_basic[\"shop_location\"])\n",
    "            sold.append(item_basic[\"sold\"])\n",
    "            price.append([item_basic[\"price_min\"], item_basic[\"price_max\"]])\n",
    "            rating_star.append(item_basic[\"item_rating\"][\"rating_star\"])\n",
    "            rating_count.append(\n",
    "                item_basic[\"item_rating\"][\"rating_count\"][1:-1])\n",
    "\n",
    "    col = [\"itemid\", \"shopid\", \"name\", \"variations\", \"brand\", \"shop_location\",\n",
    "           \"view_count\", \"sold\", \"rating_star\", \"rating_count(1* - 5*)\", \"price\"]\n",
    "    product_attr = zip(product_id, shop_id, name, variations, brand, shop_location,\n",
    "                       view_count, sold, rating_star, rating_count, price)\n",
    "    products = pd.DataFrame(list(product_attr), columns=col)\n",
    "\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_rating(itemid, shopid):\n",
    "\n",
    "    reponse = requests.get(rating_url.format(\n",
    "        itemid, 0, shopid), headers=headers)\n",
    "\n",
    "    check_status(reponse)\n",
    "\n",
    "    rating_total = json.loads(reponse.text)[\n",
    "        \"data\"][\"item_rating_summary\"][\"rating_total\"]\n",
    "\n",
    "    rating_star, comment, variations, price = [], [], [], []\n",
    "\n",
    "    for i in range(0, int(rating_total/6) + 1, 6):\n",
    "        reponse = requests.get(rating_url.format(\n",
    "            itemid, i, shopid), headers=headers)\n",
    "        print(\"\\tCrawl comments in page {}!\".format(i), end=\" \")\n",
    "        if (check_status(reponse) != True):\n",
    "            break\n",
    "        \n",
    "        rating_items = json.loads(reponse.text)[\"data\"][\"ratings\"]\n",
    "        for j in range(len(rating_items)):\n",
    "            ratings = rating_items[j]\n",
    "            rating_star.append(ratings[\"rating_star\"])\n",
    "            comment.append(ratings[\"comment\"])\n",
    "            product_items = ratings[\"product_items\"]\n",
    "            sub_variation, sub_price = [], []\n",
    "            for k in range(len(product_items)):\n",
    "                sub_variation.append(product_items[k][\"model_name\"])\n",
    "                sub_price.append(product_items[k][\"price\"])\n",
    "            variations.append(sub_variation)\n",
    "            price.append(sub_price)\n",
    "\n",
    "    col = [\"variations\", \"price\", \"rating_star\", \"comment\"]\n",
    "    ratings_cmt = pd.DataFrame(data=list(\n",
    "        zip(variations, price, rating_star, comment)), columns=col)\n",
    "    file_name = \"{},{}.csv\".format(itemid, shopid)\n",
    "    ratings_cmt.to_csv(\"./cmt_ratings/{}\".format(file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"PLEASE READ README.md TO CRAWL CORRECTLY PAGE NUMBER!!!\")\n",
    "    n_begin = int(input(\"Enter the first page: \"))\n",
    "    n_end = int(input(\"Enter the last page: \"))\n",
    "    products = crawl_product(n_begin, n_end)\n",
    "    products.to_csv(\"products.csv\", index=False)\n",
    "\n",
    "    n_b = int(input(\"Enter the first product: \"))\n",
    "    n_e = int(input(\"Enter the last product: \"))\n",
    "    products = pd.read_csv(\"products.csv\")\n",
    "    itemid = products[\"itemid\"].to_numpy()\n",
    "    shopid = products[\"shopid\"].to_numpy()\n",
    "    name = products[\"name\"].to_numpy()\n",
    "    for i in range(n_b, n_e+1):\n",
    "        print(i, name[i])\n",
    "        crawl_rating(itemid[i], shopid[i])"
   ]
  }
 ]
}